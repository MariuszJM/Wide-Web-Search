{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4602456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import datetime\n",
    "import logging\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4263437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Queries\n",
    "SEARCH_QUERIES = [\n",
    "    \"High-level overview of intelligent user interfaces and their impact on modern UI/UX design\",\n",
    "    \"Tools and frameworks for building intelligent user interfaces: A 2024 guide\"\n",
    "]\n",
    "\n",
    "# Specific Questions\n",
    "SPECIFIC_QUESTIONS = [\n",
    "    \"What are the latest trends in intelligent user interfaces, and how are they shaping user experience?\",\n",
    "    \"What are the best practices for ensuring accessibility and inclusivity in AI-powered user interfaces?\",\n",
    "]\n",
    "\n",
    "# Time Horizon in days\n",
    "TIME_HORIZON = 185  # In days\n",
    "\n",
    "# Max Outputs\n",
    "MAX_OUTPUTS = 5\n",
    "\n",
    "PLATFORM = 'google'\n",
    "SOURCES_PER_QUERY = 10\n",
    "# LLM Name\n",
    "LLM_NAME = \"ollama\"  # Available options: \"ollama\", \"groq\"\n",
    "\n",
    "# Logger Setup\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e440596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import get_llm, get_llm_json_mode\n",
    "\n",
    "# Initialize LLM\n",
    "llm = get_llm(LLM_NAME)\n",
    "llm_json_mode = get_llm_json_mode(LLM_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8a2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration data\n",
    "config_data = {\n",
    "    \"search_queries\": SEARCH_QUERIES,\n",
    "    \"specific_questions\": SPECIFIC_QUESTIONS,\n",
    "    \"platform\": PLATFORM,\n",
    "    \"time_horizon\": TIME_HORIZON,\n",
    "    \"max_outputs\": MAX_OUTPUTS,\n",
    "    \"llm_name\": LLM_NAME,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d22670",
   "metadata": {},
   "source": [
    "## Control Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a86d91",
   "metadata": {},
   "source": [
    "### Tracing \n",
    "\n",
    "Optionally, use [LangSmith](https://www.langchain.com/langsmith) for tracing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4462e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"local-llama32-rag\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43360fea",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c15ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nodes import (\n",
    "    google_retrieve_urls,\n",
    "    youtube_retrieve_urls,\n",
    "    google_process_content,\n",
    "    youtube_process_content,\n",
    "    create_embeddings,\n",
    "    semantic_search_and_grading,\n",
    "    generate_qa,\n",
    "    hallucination_check,\n",
    "    generate_summaries,\n",
    "    rank_sources,\n",
    "    save_output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d3e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edges\n",
    "\n",
    "def route_platform(state):\n",
    "    \"\"\"\n",
    "    Route to the appropriate platform-specific nodes\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    if state[\"platform\"].lower() == 'google':\n",
    "        return \"google_retrieve_urls\"\n",
    "    elif state[\"platform\"].lower() == 'youtube':\n",
    "        return \"youtube_retrieve_urls\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid platform specified in state.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Graph state is a dictionary that contains information we want to propagate to, \n",
    "    and modify in, each graph node.\n",
    "    \"\"\"\n",
    "\n",
    "    search_queries: List[str]  # List of search queries for the platform\n",
    "    specific_questions: List[str]  # List of specific questions for content filtering\n",
    "    platform: str  # Selected platform, e.g., 'google' or 'youtube'\n",
    "    llm: object  # LLM instance for text generation\n",
    "    llm_json_mode: object  # LLM instance for JSON-based output generation\n",
    "    time_horizon: int  # Time horizon in days for filtering content\n",
    "    max_outputs: int  # Maximum number of outputs to retrieve\n",
    "    logger: object  # Logger object to track progress\n",
    "    unique_urls: List[str]  # List of unique URLs retrieved from the platform\n",
    "    all_docs: List[str]  # List of documents/content retrieved from URLs\n",
    "    retriever: object  # Retriever object for semantic search\n",
    "    relevant_chunks: dict  # Relevant content chunks based on questions\n",
    "    qa_results: dict  # Q&A results after processing content\n",
    "    valid_qa_results: dict  # Validated Q&A results without hallucinations\n",
    "    summaries: dict  # Summaries for the processed sources\n",
    "    sorted_sources: List[str]  # Sources ranked based on relevance to questions\n",
    "    output_folder: str  # Folder path for saving results\n",
    "    sources_per_query: int  # Number of sources per query\n",
    "\n",
    "# Define the workflow graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"google_retrieve_urls\", google_retrieve_urls)\n",
    "workflow.add_node(\"youtube_retrieve_urls\", youtube_retrieve_urls)\n",
    "workflow.add_node(\"google_process_content\", google_process_content)\n",
    "workflow.add_node(\"youtube_process_content\", youtube_process_content)\n",
    "# workflow.add_node(\"create_embeddings\", create_embeddings)\n",
    "# workflow.add_node(\"semantic_search_and_grading\", semantic_search_and_grading)\n",
    "# workflow.add_node(\"generate_qa\", generate_qa)\n",
    "# workflow.add_node(\"hallucination_check\", hallucination_check)\n",
    "# workflow.add_node(\"generate_summaries\", generate_summaries)\n",
    "# workflow.add_node(\"rank_sources\", rank_sources)\n",
    "# workflow.add_node(\"save_output\", save_output)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_platform,\n",
    "    {\n",
    "        \"google_retrieve_urls\": \"google_retrieve_urls\",\n",
    "        \"youtube_retrieve_urls\": \"youtube_retrieve_urls\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Platform-specific flows\n",
    "workflow.add_edge(\"google_retrieve_urls\", \"google_process_content\")\n",
    "workflow.add_edge(\"youtube_retrieve_urls\", \"youtube_process_content\")\n",
    "\n",
    "# Merge flows after platform-specific processing\n",
    "workflow.add_edge(\"google_process_content\", END)\n",
    "workflow.add_edge(\"youtube_process_content\", END)\n",
    "\n",
    "# # Continue common flow\n",
    "# workflow.add_edge(\"create_embeddings\", \"semantic_search_and_grading\")\n",
    "# workflow.add_edge(\"semantic_search_and_grading\", \"generate_qa\")\n",
    "# workflow.add_edge(\"generate_qa\", \"hallucination_check\")\n",
    "# workflow.add_edge(\"hallucination_check\", \"generate_summaries\")\n",
    "# workflow.add_edge(\"generate_summaries\", \"rank_sources\")\n",
    "# workflow.add_edge(\"rank_sources\", \"save_output\")\n",
    "# workflow.add_edge(\"save_output\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297d998",
   "metadata": {},
   "source": [
    "# Run the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de3cd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the graph\n",
    "initial_state = GraphState({\n",
    "    \"search_queries\": SEARCH_QUERIES,\n",
    "    \"specific_questions\": SPECIFIC_QUESTIONS,\n",
    "    \"platform\": 'youtube',\n",
    "    \"llm\": llm,\n",
    "    \"llm_json_mode\": llm_json_mode,\n",
    "    \"time_horizon\": TIME_HORIZON,\n",
    "    \"max_outputs\": MAX_OUTPUTS,\n",
    "    \"logger\": logger,\n",
    "    \"sources_per_query\": SOURCES_PER_QUERY,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614205e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search_queries': ['High-level overview of intelligent user interfaces and their impact on modern UI/UX design', 'Tools and frameworks for building intelligent user interfaces: A 2024 guide'], 'specific_questions': ['What are the latest trends in intelligent user interfaces, and how are they shaping user experience?', 'What are the best practices for ensuring accessibility and inclusivity in AI-powered user interfaces?'], 'platform': 'youtube', 'llm': ChatOllama(model='llama3.2:latest', temperature=0.0), 'llm_json_mode': ChatOllama(model='llama3.2:latest', temperature=0.0, format='json'), 'time_horizon': 185, 'max_outputs': 5, 'logger': <Logger __main__ (INFO)>, 'sources_per_query': 10}\n",
      "\u001b[32;1m\u001b[1;3m['https://www.youtube.com/watch?v=nS1UrJnncWc&pp=ygVaSGlnaC1sZXZlbCBvdmVydmlldyBvZiBpbnRlbGxpZ2VudCB1c2VyIGludGVyZmFjZXMgYW5kIHRoZWlyIGltcGFjdCBvbiBtb2Rlcm4gVUkvVVggZGVzaWdu', 'https://www.youtube.com/watch?v=XZf5A0wcruE&pp=ygVaSGlnaC1sZXZlbCBvdmVydmlldyBvZiBpbnRlbGxpZ2VudCB1c2VyIGludGVyZmFjZXMgYW5kIHRoZWlyIGltcGFjdCBvbiBtb2Rlcm4gVUkvVVggZGVzaWdu']\u001b[0m"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/repos/wide_web_search/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1273\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1268\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1269\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1270\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1271\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1272\u001b[0m     ):\n\u001b[0;32m-> 1273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1280\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/wide_web_search/.venv/lib/python3.12/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/repos/wide_web_search/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/repos/wide_web_search/.venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/repos/wide_web_search/.venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/repos/wide_web_search/src/nodes.py:62\u001b[0m, in \u001b[0;36myoutube_retrieve_urls\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     60\u001b[0m     results \u001b[38;5;241m=\u001b[39m youtube_top_results(search_query, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sources_per_query)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m---> 62\u001b[0m         unique_urls\u001b[38;5;241m.\u001b[39madd(\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     64\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_urls\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(unique_urls)\n\u001b[1;32m     65\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(unique_urls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m initial URLs from YouTube.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "for event in graph.stream(initial_state, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8458f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
